# ğŸ›¡ï¸ Exploit, Defend, and Detect Adversarial Attacks on Image-Based AI Systems  
**An Ethical Perspective**

ğŸ‘¨â€ğŸ’» **Authors**  
- Mattia Gualandi â€” [mattia.gualandi2@studio.unibo.it](mailto:mattia.gualandi2@studio.unibo.it)  
- Alex Presepi â€” [alex.presepi@studio.unibo.it](mailto:alex.presepi@studio.unibo.it)  
- Alessandro Sciarrillo â€” [alessandr.sciarrill2@studio.unibo.it](mailto:alessandr.sciarrill2@studio.unibo.it)  

---

## ğŸ“„ Abstract  
The growing integration of deep learning models in critical domains has raised urgent concerns about their **vulnerabilities**. One of the most alarming threats is **adversarial attacks** on image-based AI systems â€” subtle perturbations to images that can mislead even the most accurate models, often without detection.  

These attacks challenge not only the **technical robustness** of AI but also raise **ethical concerns**, especially regarding human safety, fairness, and accountability.  

In this project, we:  
- ğŸ” **Review and categorize** popular adversarial attack techniques.  
- ğŸ§ª **Evaluate their impact** on standard vision models.  
- ğŸ›¡ï¸ **Design and test defenses** to counteract these attacks.  
- ğŸš¨ **Develop detection modules** to recognize corrupted inputs.  
- ğŸš— **Apply case studies** in face recognition and vehicle detection, highlighting real-world risks.  

By combining **technical** and **ethical perspectives**, we emphasize the importance of AI systems that are not only performant but also **resilient and trustworthy** under adversarial conditions.  

---

## âš™ï¸ Installation  

Clone the repository and install the required dependencies:  

```bash
pip install -r requirements.txt
```

## ğŸ“¦ Datasets  

Download the following datasets and place them inside the `datasets/` folder:  

1. ğŸ§¾ [PADetBench](https://huggingface.co/datasets/Jiawei-Lian/PADetBench/tree/main) â€” benchmark for evaluating adversarial detection.  
2. ğŸ–¼ï¸ [ImageNet-100 (validation set)](https://www.kaggle.com/datasets/ambityga/imagenet100?select=val.X) â€” subset of ImageNet for large-scale image classification.  
3. ğŸ™‚ [Face Recognition Dataset](https://www.kaggle.com/api/v1/datasets/download/vasukipatel/face-recognition-dataset) â€” dataset for face identification tasks.  

---

## ğŸš€ Features  

- ğŸ§¨ Implementation of **adversarial attacks**: PGD, DeepFool, Carlini-Wagner, and more.  
- ğŸ›¡ï¸ Evaluation of **defenses**: preprocessing, feature squeezing and adversarial training.  
- ğŸ” Development of a **detector module** to identify adversarially perturbed inputs.  
- ğŸš— Case studies on **face recognition** and **vehicle detection** to highlight real-world implications.  
- âš–ï¸ Integration of an **ethical perspective**, addressing fairness, safety, and accountability.  

---

## ğŸ“Œ Ethical Perspective  

Adversarial robustness is not only a **technical challenge** but also a matter of **ethics**.  
We emphasize:  
- ğŸ” **Security** â€” protecting systems from malicious exploitation.  
- âš–ï¸ **Accountability** â€” designing systems that remain trustworthy in safety-critical contexts.  

---

